{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split between test and train\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data.data, data.target, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remake the fp functions and bits\n",
    "def tp(pred, ytest):\n",
    "    #the predicted as 1 and being actual 1 \n",
    "    return ((pred==True) & (ytest==True)).sum()\n",
    "\n",
    "def fp(pred, ytest):\n",
    "    #the false predictions that are 1\n",
    "    return ((pred==True) & (ytest==False)).sum()\n",
    "\n",
    "def tn(pred, ytest):\n",
    "    #the correct predictions that are 0\n",
    "    return ((pred==False) & (ytest==False)).sum()\n",
    "\n",
    "def fn(pred, ytest):\n",
    "    #the false predictions that are 0\n",
    "    return ((pred==False) & (ytest==True)).sum()\n",
    "\n",
    "def tpr(pred, label):\n",
    "    return tp(pred, label) / (tp(pred, label) + fn(pred, label))\n",
    "\n",
    "def fnr(pred, label):\n",
    "    return fn(pred, label) / (fn(pred, label) + tp(pred, label))\n",
    "\n",
    "def fpr(pred, label):\n",
    "    return fp(pred, label) / (fp(pred, label) + tn(pred, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1]), array([2]), array([3]), array([4]), array([5])]\n"
     ]
    }
   ],
   "source": [
    "test_array = np.array([1, 2, 3, 4, 5])\n",
    "test_listed = np.array_split(test_array, 5)\n",
    "print(test_listed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "       1, 0, 0]), array([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 0, 0]), array([1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "       1, 0, 0]), array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "       1, 0, 0]), array([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(np.array_split(ytrain, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 50\n",
    "n_folds = 5\n",
    "def get_split(n_samples: int, n_folds) -> np.array:\n",
    "        \n",
    "        validation_begin = 0\n",
    "        validation_end = (n_samples // n_folds)\n",
    "        listed_arrays = []\n",
    "        for n in range(n_folds):\n",
    "                splits = np.ones(n_samples, dtype=bool)\n",
    "                #figure out how to slice the validation index to False\n",
    "                validation_index = 0\n",
    "                for split in range(len(splits)):\n",
    "                        if validation_begin <= validation_index <= validation_end:\n",
    "                                splits[validation_index:validation_end] = False\n",
    "                        validation_index += (n_samples // n_folds)\n",
    "                listed_arrays.append(splits)\n",
    "                validation_begin += (n_samples // n_folds)\n",
    "                validation_end += (n_samples // n_folds)\n",
    "        return np.array(listed_arrays)\n",
    "        \n",
    "        # n_per_fragment = n_samples // n_folds\n",
    "        # np.array_split(np.ones(569, ))\n",
    "        # sample_array = np.array(range(1, n_samples))\n",
    "        # bool_array = np.array_split(sample_array, n_folds)\n",
    "        # validation_index = 0\n",
    "        # for x in range(len(bool_array)):\n",
    "        #         bool_array[x][validation_index] = False\n",
    "        #         validation_index += 1\n",
    "        #         print(bool_array[x].astype(bool))\n",
    "        # return bool_array\n",
    "returned_array = get_split(n_samples, n_folds)\n",
    "returned_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 364, n_neighbors = 365",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m             scores\u001b[39m.\u001b[39mappend(all_k[(np\u001b[39m.\u001b[39marray(k_score)\u001b[39m.\u001b[39margmax())[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(scores)\u001b[39m.\u001b[39mmean\n\u001b[0;32m---> 21\u001b[0m best_k \u001b[39m=\u001b[39m cross_validation(xtrain, ytrain, \u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[99], line 15\u001b[0m, in \u001b[0;36mcross_validation\u001b[0;34m(x, y, n_folds)\u001b[0m\n\u001b[1;32m     13\u001b[0m sk_kn \u001b[39m=\u001b[39m KNeighborsClassifier(changing_k)\n\u001b[1;32m     14\u001b[0m sk_kn\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m---> 15\u001b[0m prob \u001b[39m=\u001b[39m sk_kn\u001b[39m.\u001b[39;49mpredict_proba(x_val)\n\u001b[1;32m     16\u001b[0m score \u001b[39m=\u001b[39m roc_auc_score(y_val, prob[:, \u001b[39m1\u001b[39m])\n\u001b[1;32m     17\u001b[0m k_score\u001b[39m.\u001b[39mappend(score)\n",
      "File \u001b[0;32m~/anaconda3/envs/owkin1/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:283\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return probability estimates for the test data X.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m    by lexicographic order.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    281\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    284\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/owkin1/lib/python3.9/site-packages/sklearn/neighbors/_base.py:810\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    808\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[1;32m    809\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 810\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    811\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected n_neighbors <= n_samples, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    812\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but n_samples = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, n_neighbors = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    813\u001b[0m     )\n\u001b[1;32m    815\u001b[0m n_jobs \u001b[39m=\u001b[39m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    816\u001b[0m chunked_results \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 364, n_neighbors = 365"
     ]
    }
   ],
   "source": [
    "def cross_validation(x, y, n_folds):\n",
    "    bool_array = get_split(xtrain.shape[0], n_folds)\n",
    "    scores = []\n",
    "    for mask in bool_array:\n",
    "            k_score = []\n",
    "            all_k = []\n",
    "            for changing_k in range(1, (xtrain.shape[0] - 1)):\n",
    "                all_k.append(changing_k)\n",
    "                x_train = x[mask]\n",
    "                y_train = y[mask]\n",
    "                x_val = x[~mask]\n",
    "                y_val = y[~mask]\n",
    "                sk_kn = KNeighborsClassifier(changing_k)\n",
    "                sk_kn.fit(x_train, y_train)\n",
    "                prob = sk_kn.predict_proba(x_val)\n",
    "                score = roc_auc_score(y_val, prob[:, 1])\n",
    "                k_score.append(score)\n",
    "            scores.append(all_k[(np.array(k_score).argmax())[0]])\n",
    "    return np.array(scores).mean\n",
    "\n",
    "best_k = cross_validation(xtrain, ytrain, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (91844326.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[83], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def cross_validation_two(xtrain, ytrain, 5):\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#cross validate the train data to select k\n",
    "def cross_validation_two(xtrain, ytrain):\n",
    "    split_train, split_target = np.array_split(xtrain, 5), np.array_split(ytrain, 5)\n",
    "    k_values = []\n",
    "    for subset in range(len(split_train)):\n",
    "        validate_set = split_train[subset]\n",
    "        scores = []\n",
    "        for changing_k in range(1, (xtrain.shape[0] - 1)):\n",
    "            sk_kn = KNeighborsClassifier(changing_k)\n",
    "            data_no_validate = []\n",
    "            target_no_validate = []\n",
    "            for j, (sub1, sub2) in enumerate(zip(split_train, split_target)):\n",
    "                if j == subset: \n",
    "                    pass\n",
    "                else:\n",
    "                    data_no_validate.append(sub1)\n",
    "                    target_no_validate.append(sub2)\n",
    "            print(data_no_validate)\n",
    "            print(target_no_validate)\n",
    "            sk_kn.fit(data_no_validate, target_no_validate)\n",
    "            pred = sk_kn.predict(validate_set)\n",
    "            prob = sk_kn.predict_proba(validate_set)\n",
    "            print(pred)\n",
    "            scores.append(roc_auc_score(pred, prob[:, 1]))\n",
    "            scores_arr = np.array(scores)\n",
    "        best_score_k = scores_arr.argmax()[-1]\n",
    "        k_values.append(best_score_k)\n",
    "    ks_array = np.array(k_values)\n",
    "    return ks_array.mean\n",
    "best_k = cross_validation(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "/var/folders/hs/9wxtjrjx2k718tlbtzyfl1dm0000gn/T/ipykernel_27836/2234646173.py:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  sample_list = [[1, 2][3, 4], [5, 6]]\n",
      "/var/folders/hs/9wxtjrjx2k718tlbtzyfl1dm0000gn/T/ipykernel_27836/2234646173.py:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  sample_list = [[1, 2][3, 4], [5, 6]]\n",
      "/var/folders/hs/9wxtjrjx2k718tlbtzyfl1dm0000gn/T/ipykernel_27836/2234646173.py:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  sample_list = [[1, 2][3, 4], [5, 6]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample_list \u001b[39m=\u001b[39m [[\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m][\u001b[39m3\u001b[39;49m, \u001b[39m4\u001b[39;49m], [\u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m]]\n\u001b[1;32m      2\u001b[0m mask \u001b[39m=\u001b[39m [\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m]\n\u001b[1;32m      3\u001b[0m sample_list[\u001b[39m1\u001b[39m][mask]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "sample_list = [[1, 2][3, 4], [5, 6]]\n",
    "mask = [True, False]\n",
    "sample_list[1][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#mean the k and then use it in auc for the test\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#do data with this k, then test\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#do i fit all the training?\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m kn_with_best_k \u001b[39m=\u001b[39m KNeighborsClassifier(best_k)\n\u001b[1;32m      5\u001b[0m kn_with_best_k\u001b[39m.\u001b[39mfit(xtrain, ytrain)\n\u001b[1;32m      6\u001b[0m test_pred \u001b[39m=\u001b[39m kn_with_best_k\u001b[39m.\u001b[39mpredict(xtest)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_k' is not defined"
     ]
    }
   ],
   "source": [
    "#mean the k and then use it in auc for the test\n",
    "#do data with this k, then test\n",
    "#do i fit all the training?\n",
    "kn_with_best_k = KNeighborsClassifier(best_k)\n",
    "kn_with_best_k.fit(xtrain, ytrain)\n",
    "test_pred = kn_with_best_k.predict(xtest)\n",
    "test_proba = kn_with_best_k.predict_proba(xtest)\n",
    "best_k_auc_score = roc_auc_score(test_pred, test_proba[:, 1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "owkin1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
